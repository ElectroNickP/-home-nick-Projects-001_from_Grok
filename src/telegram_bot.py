import os
import time
import asyncio
import logging
import openai
from pydub import AudioSegment
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.client.bot import DefaultBotProperties

from src.config_manager import CONVERSATIONS, CONVERSATIONS_LOCK, OPENAI_LOCK

logger = logging.getLogger(__name__)

async def transcribe_audio(file_path):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é OpenAI Whisper."""
    try:
        with open(file_path, "rb") as audio_file:
            transcript = await asyncio.to_thread(openai.audio.transcriptions.create,
                model="whisper-1",
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

async def ask_openai(prompt, config, conversation_key):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ OpenAI –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç."""
    try:
        with OPENAI_LOCK:
            client = openai.OpenAI(api_key=config["openai_api_key"])

            with CONVERSATIONS_LOCK:
                if conversation_key in CONVERSATIONS:
                    thread_id = CONVERSATIONS[conversation_key]["thread_id"]
                else:
                    thread_resp = client.beta.threads.create()
                    thread_id = thread_resp.id
                    CONVERSATIONS[conversation_key] = {"thread_id": thread_id, "messages": []}

            client.beta.threads.messages.create(thread_id=thread_id, role="user", content=prompt)
            run_resp = client.beta.threads.runs.create(thread_id=thread_id, assistant_id=config["assistant_id"])

        start_time = time.time()
        timeout = 45
        while True:
            with OPENAI_LOCK:
                status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_resp.id).status
            if status == "completed":
                break
            if time.time() - start_time > timeout:
                return "‚ùå –û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI."
            await asyncio.sleep(2)

        with OPENAI_LOCK:
            messages = client.beta.threads.messages.list(thread_id=thread_id).data

        with CONVERSATIONS_LOCK:
            CONVERSATIONS[conversation_key]["messages"] = [
                {"role": msg.role, "content": msg.content[0].text.value, "timestamp": msg.created_at}
                for msg in messages
            ]
        return messages[0].content[0].text.value
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ ask_openai:")
        return f"‚ùå –û—à–∏–±–∫–∞: {e}"

async def aiogram_bot(config, stop_event):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ aiogram."""
    bot = Bot(token=config["telegram_token"], default=DefaultBotProperties(parse_mode="HTML"))
    dp = Dispatcher()

    @dp.message(Command(commands=["start"]))
    async def cmd_start(message: types.Message):
        text = f"üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç {config.get('bot_name', '')}. –ù–∞–ø–∏—à–∏ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."
        await message.answer(text)

    @dp.message(types.ContentType.VOICE)
    async def handle_voice_message(message: types.Message):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
        voice_file_id = message.voice.file_id
        file_info = await bot.get_file(voice_file_id)
        file_path = file_info.file_path

        ogg_filename = f"{voice_file_id}.ogg"
        mp3_filename = f"{voice_file_id}.mp3"

        await bot.download_file(file_path, ogg_filename)

        try:
            audio = AudioSegment.from_ogg(ogg_filename)
            audio.export(mp3_filename, format="mp3")

            with OPENAI_LOCK:
                openai.api_key = config["openai_api_key"]
                transcribed_text = await transcribe_audio(mp3_filename)

            if transcribed_text:
                await message.reply(f"<i>–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è: \"{transcribed_text}\"</i>")
                conversation_key = f"{config['telegram_token']}_{message.from_user.id}"
                response = await ask_openai(transcribed_text, config, conversation_key)
                await message.answer(response)
            else:
                await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")
        finally:
            if os.path.exists(ogg_filename):
                os.remove(ogg_filename)
            if os.path.exists(mp3_filename):
                os.remove(mp3_filename)

    @dp.message()
    async def handle_text_message(message: types.Message):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
        conversation_key = f"{config['telegram_token']}_{message.from_user.id}"
        response = await ask_openai(message.text, config, conversation_key)
        await message.answer(response)

    logger.info(f"–ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞ {config.get('bot_name', '')}...")
    try:
        await bot.delete_webhook(drop_pending_updates=True)
        stop_wait_task = asyncio.create_task(stop_event.wait())
        polling_task = asyncio.create_task(dp.start_polling(bot, handle_signals=False))
        await asyncio.wait([polling_task, stop_wait_task], return_when=asyncio.FIRST_COMPLETED)
        if stop_wait_task.done():
            polling_task.cancel()
            logger.info(f"–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–æ—Ç–∞ {config.get('bot_name', '')} –ø–æ –∑–∞–ø—Ä–æ—Å—É.")
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –≤ –±–æ—Ç–µ {config.get('bot_name', '')}:")
    finally:
        await bot.session.close()
